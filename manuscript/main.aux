\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{mittal2015survey}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\citation{cheng2018deep,toderici2017full,balle2016end}
\@writefile{toc}{\contentsline {section}{\numberline {2}Intuition of the autoencoder}{2}{section.2}\protected@file@percent }
\newlabel{sec:intuition}{{2}{2}{Intuition of the autoencoder}{section.2}{}}
\citation{lecun1998gradient}
\@writefile{toc}{\contentsline {section}{\numberline {3}Dataset}{3}{section.3}\protected@file@percent }
\newlabel{sec:dataset}{{3}{3}{Dataset}{section.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental method}{3}{section.4}\protected@file@percent }
\newlabel{sec:experimental-method}{{4}{3}{Experimental method}{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{4}{section.5}\protected@file@percent }
\newlabel{sec:results}{{5}{4}{Results}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{4}{section.6}\protected@file@percent }
\newlabel{sec:conclusion}{{6}{4}{Conclusion}{section.6}{}}
\bibdata{main}
\bibcite{balle2016end}{{1}{2016}{{Ball{\'e} et~al.}}{{Ball{\'e}, Laparra, and Simoncelli}}}
\bibcite{cheng2018deep}{{2}{2018}{{Cheng et~al.}}{{Cheng, Sun, Takeuchi, and Katto}}}
\bibcite{lecun1998gradient}{{3}{1998}{{LeCun et~al.}}{{LeCun, Bottou, Bengio, and Haffner}}}
\bibcite{mittal2015survey}{{4}{2015}{{Mittal and Vetter}}{{}}}
\bibcite{toderici2017full}{{5}{2017}{{Toderici et~al.}}{{Toderici, Vincent, Johnston, Jin~Hwang, Minnen, Shor, and Covell}}}
\bibstyle{plainnat}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Examples of MNIST instances\relax }}{7}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:instance-examples}{{1}{7}{Examples of MNIST instances\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Distribution of classes in MNIST dataset\relax }}{7}{figure.caption.4}\protected@file@percent }
\newlabel{fig:class-distributions}{{2}{7}{Distribution of classes in MNIST dataset\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Generic autoencoder architecture, without bias\relax }}{8}{figure.caption.5}\protected@file@percent }
\newlabel{fig:autoencoder-diagram}{{3}{8}{Generic autoencoder architecture, without bias\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Generic autoencoder architecture, with bias\relax }}{9}{figure.caption.6}\protected@file@percent }
\newlabel{fig:autoencoder-diagram-bias}{{4}{9}{Generic autoencoder architecture, with bias\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Reconstruction mean-squared error throughout training phase, disaggregated by network architecture\relax }}{10}{figure.caption.7}\protected@file@percent }
\newlabel{fig:training-loss}{{5}{10}{Reconstruction mean-squared error throughout training phase, disaggregated by network architecture\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Reconstructed instances disaggregated by compression ratio (no bias units)\relax }}{11}{figure.caption.8}\protected@file@percent }
\newlabel{fig:decoded-instances}{{6}{11}{Reconstructed instances disaggregated by compression ratio (no bias units)\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Reconstructed instances disaggregated by compression ratio (including bias units)\relax }}{12}{figure.caption.9}\protected@file@percent }
\newlabel{fig:decoded-instances}{{7}{12}{Reconstructed instances disaggregated by compression ratio (including bias units)\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Mean-squared error (MSE) for reconstructed images disaggregated by MNIST class\relax }}{13}{figure.caption.10}\protected@file@percent }
\newlabel{fig:decoded-instances}{{8}{13}{Mean-squared error (MSE) for reconstructed images disaggregated by MNIST class\relax }{figure.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Mean-squared error (MSE) for reconstructed images \relax }}{15}{table.caption.12}\protected@file@percent }
\newlabel{table:mse-final}{{1}{15}{Mean-squared error (MSE) for reconstructed images \relax }{table.caption.12}{}}
\gdef \@abspage@last{15}
