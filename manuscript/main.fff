\begin{figure}
    \caption{Examples of MNIST instances}
\label{fig:instance-examples}
\includegraphics[width=1.0\textwidth]{graphics/instance_examples.pdf}
    \textbf{Notes}: Example instances from the MNIST dataset. Each instance is normalised in grey-scale (0-255), and aligned by translating the centre of pixel-mass to be positioned at the centre of a 28x28 pixel grid.
\end{figure}
\efloatseparator
 
\begin{figure}
    \caption{Distribution of classes in MNIST dataset}
\label{fig:class-distributions}
\includegraphics[width=1.0\textwidth]{graphics/class_distribution.pdf}
    \textbf{Notes}: Class distribution of digit instances (0 - 9) in the full MNIST dataset, across both training (N=60,000) and validation (N=10,000) partitions.
\end{figure}
\efloatseparator
 
\begin{figure}
    \caption{Generic autoencoder architecture, without bias}
\label{fig:autoencoder-diagram}
\includegraphics[width=1.0\textwidth]{graphics/autoencoder_diagram.pdf}
    \textbf{Notes}: Input and output layers each contain 784 nodes respectively, in congruence with the dimensions of MNIST image instance vectors. Intermediate nodes are omitted for ease of interpretability. Hidden layers contain a variable number of nodes, $N$, varied across seven values: 2, 4, 8, 14, 28, 56, and 112. Encoding of inputs occurs through weighting of activations between input and hidden layers. Image reconstruction occurs through weighting of activations between hidden and output layers.
\end{figure}
\efloatseparator
 
\begin{figure}
    \caption{Generic autoencoder architecture, with bias}
\label{fig:autoencoder-diagram-bias}
\includegraphics[width=1.0\textwidth]{graphics/autoencoder_diagram_bias.pdf}
    \textbf{Notes}: Input and output layers each contain 784 nodes respectively, in congruence with the dimensions of MNIST image instance vectors. Intermediate nodes are omitted for ease of interpretability. Hidden layers contain a variable number of nodes, $N$, varied across seven values: 2, 4, 8, 14, 28, 56, and 112. A  constant bias affects activations in hidden and output nodes differentially through learned bias weights. Encoding of inputs occurs through weighting of activations between input and hidden layers. Image reconstruction occurs through weighting of activations between hidden and output layers.
\end{figure}
\efloatseparator
 
\begin{figure}
    \caption{Reconstruction mean-squared error throughout training phase, disaggregated by network architecture}
\label{fig:training-loss}
\includegraphics[width=1.0\textwidth]{graphics/model_loss.pdf}
    \textbf{Notes}: Mean-squared error (MSE) of autoencoder networks across validation partition of MNIST dataset. MSE was calculated through forward propogation of MNIST validation instances (N=10,000) using trained weights at each discrete training timestep. Learning rate for each model was set at 0.01.
\end{figure}
\efloatseparator
 
\begin{figure}
    \caption{Reconstructed instances disaggregated by compression ratio (no bias units)}
\label{fig:decoded-instances}
\includegraphics[width=1.0\textwidth]{graphics/decoded_instances.pdf}
    \textbf{Notes}: Reconstructed images are generated by encoding and decoding a stimulus image using a trained autoencoder networks with varying hidden layers, and bias set to zero. Columns separate reconstructed images by compression ratio (CR). Rows separate reconstructed images by the input stimulus (uncompressed) image. The first entry in each row is the stimulus image used to generate the following reconstructions.
\end{figure}
\efloatseparator
 
\begin{figure}
    \caption{Reconstructed instances disaggregated by compression ratio (including bias units)}
\label{fig:decoded-instances}
\includegraphics[width=1.0\textwidth]{graphics/decoded_instances_bias.pdf}
    \textbf{Notes}: Reconstructed images are generated by encoding and decoding a stimulus image using a trained autoencoder networks with varying hidden layers, and bias units included. Columns separate reconstructed images by compression ratio (CR). Rows separate reconstructed images by the input stimulus (uncompressed) image. The first entry in each row is the stimulus image used to generate the following reconstructions.
\end{figure}
\efloatseparator
 
\begin{figure}
    \caption{Mean-squared error (MSE) for reconstructed images disaggregated by MNIST class}
\label{fig:decoded-instances}
\includegraphics[width=1.0\textwidth]{graphics/mse_by_class.pdf}
    \textbf{Notes}: Mean squared error (MSE) across validation partition of MNIST dataset (N=10,000), disaggregated by annotated class of image instance. MSE is calculated after training models for 50 epochs. Autoencoder network architectures are split by compression ratio (CR), and inclusion of bias units.
\end{figure}
