% Introduction


\noindent
Ours is the age of information: where digital data is ubiquitous, and computational resources are in consequently constrained supply.
In this climate, a fundamental problem presents itself in the efficient management of information to limit the computational expense of information exchange.
% Indeed, the speed at which information can be exchanged is constrained by the limits of our computational systems, and the ingenuity of data-management techniques to reduce the computational expense of information exchange.
On this account, data-compression techniques seek to alleviate the computational burden of sending and storing digital information by transforming data to compressed representations of reduced size.
Practical applications of such techniques can be broadly divided into one of two categories: lossless compression; and lossy compression.
Lossless compression refers to the class of compression algorithms that target perfect reconstruction of input data from compressed formats.
While such techniques offer uncompromised data-accuracy between compressed and uncompressed formats, recent reports show that practical applications rarely achieve compression ratios in excess of two- to four-times the size of the original data.
On the other hand, lossy data-compression techniques are able to achieve exceptionally high compression ratios at the expense of degraded data accuracy.
High compression-ratios substantially lower file sizes, and thereby reduce the computational expense of storing and exchanging information. 
Accordingly, in scenarios where degradation in accuracy of reconstructed data is less sensitive to reductions in file-size and less likely to be noticed by end-users (such as in the case of image compression), lossy techniques present an attractive approach to compression. 

Autoencoders are representation-learning applications of unsupervised artificial neural networks (ANNs), that seek to learn fundamental representations of high-dimensional data.
Indeed, several works take advantage of the ability of autoencoders to learn low-dimension representations of data to  


